{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0c68db-fe09-425f-bbd2-56d77335d38c",
   "metadata": {},
   "source": [
    "# Tutorial notebook for working Planetary Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e6d5c-1563-46bf-880a-c0345bbfa528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add the src directory to the path so that we can import generic functions\n",
    "sys.path.insert(0, \"src\")\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Sometimes you need libraries which are not included in the planetary computer image. That's\n",
    "# generally not a problem because you can install them with pip.\n",
    "os.system(\"pip install python-dotenv -q\")\n",
    "\n",
    "import dask_geopandas\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import pystac\n",
    "import shapely\n",
    "from dotenv import load_dotenv\n",
    "from ipyleaflet import Map, basemaps\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# tokens to access data in private containers\n",
    "sas_token = os.getenv(\"AZURE_STORAGE_SAS_TOKEN\")\n",
    "coclico_storage_options = {\"account_name\": \"coclico\", \"credential\": sas_token}\n",
    "\n",
    "# disable logging messages from azure\n",
    "logging.getLogger(\"azure\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d58238-05c3-40c8-b753-3901f649ea6b",
   "metadata": {},
   "source": [
    "## Load from STAC catalog\n",
    "\n",
    "Load the transects from our CoCliCo STAC catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ec243-beaa-4493-9c94-4160246cc640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coclico_catalog = pystac.Catalog.from_file(\n",
    "    \"https://coclico.blob.core.windows.net/stac/v1/catalog.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b379059-a299-4014-8948-91a7ae01aab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coclico_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c085153-ad6c-40e1-a3ef-e52e803b1ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(coclico_catalog.get_all_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13084c-06a8-4397-b173-ab4224c93a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcts = coclico_catalog.get_child(\"gcts-2000m\")\n",
    "gcts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daeb662",
   "metadata": {},
   "source": [
    "### Use a dynamic map to extract data by region of interest\n",
    "\n",
    "The IPyleaflet map below can be used to find the bbox coordinates of a certain region.\n",
    "Zoom to the area where you want to extract data and run the next cell. Please keep in\n",
    "mind to wait 1 second because the map has to be rendered before the coordinates can be\n",
    "extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e12c5b-27a3-4a0c-8ad9-0e92c427d7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = Map(basemap=basemaps.Esri.WorldImagery, scroll_wheel_zoom=True)\n",
    "m.center = 43.406241, -2.976665\n",
    "m.zoom = 9\n",
    "m.layout.height = \"800px\"\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcbc04-d50b-4d1e-88d3-c94a4948b2cc",
   "metadata": {},
   "source": [
    "## IMPORTANT NOTE: Wait for the map to render before you run the next cell\n",
    "\n",
    "rendering the map takes a second, so you need to pause 1 second before running the next cell otherwise you cannot parse the north/west/east/south bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a318969-be1b-42a3-9c4a-eb7f92d75006",
   "metadata": {},
   "source": [
    "## Import functions from project directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085cbb9-95f1-4a1f-9ea5-fe5ec79e9365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bilbao.utils import geo_bbox\n",
    "\n",
    "# this makes a GeoPandas dataframe from the DynamicMap that is rendered above\n",
    "roi = geo_bbox(m.west, m.south, m.east, m.north)\n",
    "roi.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64c44d-5b7a-483c-b679-8ab75d9a7049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# makes a list of all items (data partitions) in the GCTS STAC catalog\n",
    "items = list(gcts.get_all_items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90664c-7b47-467b-8699-774033fb6481",
   "metadata": {},
   "source": [
    "## The dataset is partitioned into geospatial chunks\n",
    "\n",
    "The dataset is divided into different chunks, that each span a different region of the world. In the next cell\n",
    "we read the spatial extends of each chunk and compose that into a GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c951272-54e6-4794-bb26-9fd1adbe5aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bboxes = pd.concat([geo_bbox(*i.to_dict()[\"bbox\"]) for i in items])\n",
    "bboxes = bboxes.reset_index(drop=True)\n",
    "bboxes.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea0f0b-02c6-4260-8b0d-91f5f15b7b52",
   "metadata": {},
   "source": [
    "## Now we can find the bboxes that cover our region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8fd11-20a9-4b85-b567-b26c02363631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bboxes_roi = gpd.sjoin(bboxes, roi)[bboxes.columns]\n",
    "items_roi = [items[i] for i in bboxes_roi.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab621b4-54e0-4cfd-8a26-0a7c47074cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565af5c-e2d2-4958-b7ae-6a68be2d1b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items_roi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb013d49-f2c8-4c98-ba73-54df72e3b526",
   "metadata": {},
   "source": [
    "## The STAC items contain references to where the data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4db663-c2db-4696-8e46-d0222212b32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hrefs = [i.assets[\"data\"].href for i in items_roi]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7af9a-a990-41ae-b67b-6de0e372d154",
   "metadata": {},
   "source": [
    "## Cloud based data\n",
    "\n",
    "The href that you see below is a url to a cloud bucket with the transects for the area of interest. The prefix \"az://\" is the protocol for Azure cloud storage. So if you don't have a STAC catalog write out the href's yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9e953-42df-45b5-ab7f-c77693de90c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa22417-2ec9-4c07-a1b5-1147f6cdb510",
   "metadata": {},
   "source": [
    "## Reading the transect partitions that span our region of interest \n",
    "\n",
    "We will read the data from cloud storage - but only the data that spans our region of interest (the DynamicMap above). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39ba52-02d0-4644-8f7d-99d0137d033f",
   "metadata": {},
   "source": [
    "## Dask dataframes are lazy\n",
    "\n",
    "These dataframes are not in memory yet. We still have to trigger the compute (see cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e12b6b-1dc3-4dad-8775-dddcdffd19d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask_geopandas.read_parquet(hrefs, storage_options=coclico_storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4ea84-3da7-4229-8f33-a270626affeb",
   "metadata": {},
   "source": [
    "## Compute the transects that span our region of interest\n",
    "\n",
    "The transects are not in memory yet. In the next cell we will trigger the retrieval from cloud storage to local client by doing a `ddf.compute()` call. Note that we can also mix in regular Pandas operations, like sorting. Currently the transects are sorted by QuadKey to optimize fast read access by filter pushdown. If we want them sorted along the coastline we can do that by sorting the tr_name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ba2a9-3f79-4d02-8a3d-fcf62b2bccf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "transects = dask_geopandas.read_parquet(hrefs, storage_options=coclico_storage_options)\n",
    "transects = (\n",
    "    transects.sjoin(\n",
    "        dask_geopandas.from_geopandas(roi.to_crs(transects.crs), npartitions=1)\n",
    "    )\n",
    "    .drop(columns=[\"index_right\"])\n",
    "    .sort_values(\"tr_name\")\n",
    "    .compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb217d-3f98-4fc0-b6bb-1cf080d1464e",
   "metadata": {},
   "source": [
    "## Show the first lines of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13195a1f-8435-42a9-9d68-cb87b0f526b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d69ff-744b-4cd3-854e-e1fa8829bd36",
   "metadata": {},
   "source": [
    "## Holoviews interactive visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9820ddd-e325-47ac-bd83-73848484953e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import hvplot.pandas\n",
    "\n",
    "transects_plot = (\n",
    "    transects[[\"geometry\", \"bearing\"]]\n",
    "    .sample(500)\n",
    "    .hvplot(\n",
    "        geo=True,\n",
    "        tiles=\"ESRI\",\n",
    "        color=\"bearing\",\n",
    "        cmap=cc.CET_C10,\n",
    "        width=700,\n",
    "        height=500,\n",
    "        clabel=\"North bearing [deg]\",\n",
    "        xlabel=\"Longitude [deg]\",\n",
    "        ylabel=\"Latitude [deg]\",\n",
    "        title=\"Cross-shore transects (100m alongshore), Euskadi.\",\n",
    "        colorbar=True,\n",
    "        tools=[\"wheel_zoom\"],\n",
    "    )\n",
    ")\n",
    "transects_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2f07a-325a-4166-a43c-a3835916e803",
   "metadata": {},
   "source": [
    "## Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658de1aa-678c-4abc-ac49-35b980936f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask_gateway\n",
    "\n",
    "cluster = dask_gateway.GatewayCluster()\n",
    "client = cluster.get_client()\n",
    "cluster.adapt(minimum=2, maximum=50)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090458cd-3bba-4b22-bbae-66219be98962",
   "metadata": {},
   "source": [
    "## Accessing ERA 5 for our region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3d37e-c6e8-4424-acca-bfa955c556eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n",
    ")\n",
    "\n",
    "time_range = \"2020-01-01/2023-12-31\"\n",
    "bbox = [m.west, m.south, m.east, m.north]\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=[\"era5-pds\"],\n",
    "    bbox=bbox,\n",
    "    datetime=time_range,\n",
    "    query={\"era5:kind\": {\"eq\": \"an\"}},\n",
    ")\n",
    "items = search.get_all_items()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ccf6c4-4bee-45a1-8332-6616ee05f16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item = items[0]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef0052-4b45-4a15-b94c-3e91d3e8da60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import planetary_computer as pc\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import rioxarray\n",
    "\n",
    "item = items[0]\n",
    "signed_item = pc.sign(item)\n",
    "datasets = [\n",
    "    xr.open_dataset(asset.href, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    for asset in signed_item.assets.values()\n",
    "]\n",
    "\n",
    "ds = xr.combine_by_coords(datasets, join=\"exact\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d0510-9e7a-49d9-a8ac-71575149adb3",
   "metadata": {},
   "source": [
    "## Datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4402fa0-c911-4263-bef0-874f637718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.air_pressure_at_mean_sea_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c05925-9c42-465a-a7c1-8fe88f48358a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da = ds.air_pressure_at_mean_sea_level.mean(\"time\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f660caf-689b-4ca6-8897-2a30351a5848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da = da.rio.write_crs(4326).rio.write_nodata(np.nan)\n",
    "da.hvplot(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    geo=True,\n",
    "    tiles=\"EsriImagery\",\n",
    "    rasterize=True,\n",
    "    width=700,\n",
    "    height=500,\n",
    "    title=\"Mean Air Pressure (2020 - 2023)\",\n",
    "    colorbar=True,\n",
    "    clabel=\"Air Pressure [Pa]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb0a12-d88b-4cc7-8737-c69eaad417bb",
   "metadata": {},
   "source": [
    "## Compute feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc7667-1e01-4405-8548-769ccd1c9c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from astropy.convolution import convolve\n",
    "import warnings\n",
    "\n",
    "def standard_deviation(\n",
    "    image: np.ndarray, radius: int, nodata: float | int = np.nan\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the standard deviation of an image using a moving window of\n",
    "    specified radius with astropy's convolution library.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): 2D array containing the pixel intensities of a single-band image.\n",
    "        radius (int): Radius defining the moving window used to calculate the standard deviation.\n",
    "                    For example, radius = 1 will produce a 3x3 moving window.\n",
    "        nodata (float, optional): Value to replace NaN results with. Defaults to np.nan.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 2D array containing the standard deviation of the image.\n",
    "\n",
    "    Example:\n",
    "        >>> img = np.random.random((100, 100))\n",
    "        >>> std_img = standard_deviation(img, radius=1)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create kernel once\n",
    "    win_rows, win_cols = radius * 2 + 1, radius * 2 + 1\n",
    "    kernel = np.ones((win_rows, win_cols))\n",
    "\n",
    "    # Pre-calculate square of image\n",
    "    image_sq = image**2\n",
    "\n",
    "    # First pad the image and its square\n",
    "    image_padded = np.pad(image, radius, \"reflect\")\n",
    "    image_sq_padded = np.pad(image_sq, radius, \"reflect\")\n",
    "\n",
    "    # Calculate std with uniform filters\n",
    "    win_mean = convolve(\n",
    "        image_padded,\n",
    "        kernel,\n",
    "        boundary=\"extend\",\n",
    "        normalize_kernel=True,\n",
    "        nan_treatment=\"interpolate\",\n",
    "        preserve_nan=True,\n",
    "    )\n",
    "    win_sqr_mean = convolve(\n",
    "        image_sq_padded,\n",
    "        kernel,\n",
    "        boundary=\"extend\",\n",
    "        normalize_kernel=True,\n",
    "        nan_treatment=\"interpolate\",\n",
    "        preserve_nan=True,\n",
    "    )\n",
    "    win_var = win_sqr_mean - win_mean**2\n",
    "\n",
    "    # Ignore RuntimeWarnings in the sqrt calculation\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in sqrt\")\n",
    "        win_std = np.sqrt(win_var)\n",
    "\n",
    "    # Remove padding\n",
    "    win_std = win_std[radius:-radius, radius:-radius]\n",
    "\n",
    "    # After computing standard deviation, replace NaN values with nodata\n",
    "    win_std[np.isnan(win_std)] = nodata\n",
    "\n",
    "    return win_std\n",
    "\n",
    "da_stdev = xr.apply_ufunc(\n",
    "        standard_deviation,\n",
    "        da,\n",
    "        input_core_dims=[[\"lon\", \"lat\"]],\n",
    "        output_core_dims=[[\"lon\", \"lat\"]],\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={\"radius\": 2, \"nodata\": np.nan},\n",
    "        output_dtypes=[\"f4\"],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae453c-fa4c-4a4d-aff4-673a39883319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da_stdev.rio.write_nodata(np.nan).rio.write_crs(4326).hvplot(x=\"lon\", y=\"lat\", geo=True, rasterize=True, title=\"St. Dev in Air Pressure\", clabel=\"St. dev in Air pressure (Pa)\", tiles=\"ESRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76868a-e79f-4be0-91a8-4921539b0324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4db1251b-b5a7-419c-a3d7-933da5ec1d54",
   "metadata": {},
   "source": [
    "## Mapping raster data onto vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df143f-8c99-4f06-ae7f-33ce3512a3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lons, lats = transects.lon.values, transects.lat.values\n",
    "lons = lons + 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7d432-31b2-4f10-aa40-6490b37d0cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transects_st_dev_air_pressure = [da_stdev.sel(lon=lon, lat=lat, method=\"nearest\").item() for lon, lat in zip(lons, lats)]\n",
    "transects[\"st_dev_air_pressure\"] = transects_st_dev_air_pressure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4553ee-1eb2-4ac8-a239-3d045ae50390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import hvplot.pandas\n",
    "\n",
    "transects_plot = (\n",
    "    transects[[\"geometry\", \"st_dev_air_pressure\"]]\n",
    "    .sample(500)\n",
    "    .hvplot(\n",
    "        geo=True,\n",
    "        tiles=\"ESRI\",\n",
    "        color=\"st_dev_air_pressure\",\n",
    "        cmap=cc.CET_D8[::-1],\n",
    "        width=700,\n",
    "        height=500,\n",
    "        clabel=\"St. Dev. Air Pressure (Pa)\",\n",
    "        xlabel=\"Longitude [deg]\",\n",
    "        ylabel=\"Latitude [deg]\",\n",
    "        title=\"St. Dev. Air. Pressure per transect, Euskadi.\",\n",
    "        colorbar=True,\n",
    "        tools=[\"wheel_zoom\"],\n",
    "    )\n",
    ")\n",
    "transects_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9507c-387b-48fb-ba71-e21bb960de6d",
   "metadata": {},
   "source": [
    "## Clipping raster to region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a99374-2ac4-4864-8a6b-1ccbf51acf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbox_translate = [bbox[0] + 180, bbox[1], bbox[2]+180, bbox[3]]\n",
    "bbox_as_geojson = shapely.geometry.mapping(shapely.box(*bbox_translate))\n",
    "da.rio.clip([bbox_as_geojson])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
